{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from trectools import TrecTopics, TrecQrel\n",
    "from vectors import MultiCCA, VectorVocabField\n",
    "from torchtext.data import Field, Example, TabularDataset, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tqdm.monitor_interval = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = pd.read_csv('docs.csv')\n",
    "docs['filename'] = docs['id']\n",
    "docs = docs.drop('id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics = TrecTopics.from_file(\n",
    "    '../material/CLEF/TOPICS00-04/f00-03', \n",
    "    topic_tag='top', numberid_tag='num', number_attr=False, querytext_tag='fr-title'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids, queries = [], []\n",
    "\n",
    "for k, v in topics.topics.items():\n",
    "    ids.append(int(k[1:]))\n",
    "    queries.append(v)\n",
    "    \n",
    "queries = pd.DataFrame({'query': ids, 'qtext': queries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qrels = TrecQrel('../material/CLEF/QRELS00-04/qrels_french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = qrels.qrels_data.merge(docs, on=['filename'], how='left').merge(queries, on='query', how='left')\n",
    "data = data[data['query'] <= 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sampled = np.random.choice(data[data.rel == 0].index.values, 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data = data[data.index.isin(sampled)].append(data[data.rel == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[data['query'] <= 150]\n",
    "test = data[data['query'] > 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')\n",
    "test.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['query', 'q0', 'filename', 'rel', 'text', 'title', 'qtext'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numericalize the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors = MultiCCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def preprocess(l):\n",
    "    \"\"\"\n",
    "    remove the punctuation from the string\n",
    "    \"\"\"\n",
    "    nopunct = ['fr:' + s.translate(translator) for s in l]\n",
    "    return [s for s in nopunct if s]\n",
    "\n",
    "def sort_key(ex):\n",
    "    \"\"\"\n",
    "    needed because `split` returns a plain Dataset, and thus doesn't account\n",
    "    for sorting examples based on text\n",
    "    \"\"\"\n",
    "    return len(ex.text)\n",
    "\n",
    "title_field = VectorVocabField(lower=True, preprocessing=preprocess)\n",
    "query_field = VectorVocabField(lower=True, preprocessing=preprocess)\n",
    "label_field = Field(sequential=False, unk_token=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = TabularDataset.splits(\n",
    "    path='./', train='train.csv', test='test.csv', format='csv',\n",
    "    fields = [('ignore', None),\n",
    "              ('queryid', None),\n",
    "              ('q0', None),\n",
    "              ('filename', None),\n",
    "              ('label', label_field),\n",
    "              ('text', None),\n",
    "              ('title', title_field),\n",
    "              ('query', query_field)],\n",
    "    filter_pred=lambda ex: ex.label in ['0', '1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_field.build_vocab(train, vectors=vectors)\n",
    "query_field.build_vocab(train, vectors=vectors)\n",
    "label_field.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = BucketIterator.splits(\n",
    "    datasets=(train,test), batch_sizes=(128, 2096), sort_key=lambda x: len(x.query), repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SiameseDAN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, pretrained_embeddings, \n",
    "                 num_filters=100, window_sizes=(3, 4, 5), mode='static', num_classes=2):\n",
    "        super(SiameseDAN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "        self.embedding.weight.requires_grad = (mode == 'nonstatic')\n",
    "        \n",
    "        self.hidden = nn.Linear(embedding_dim, num_filters)\n",
    "        self.norm_hidden = nn.BatchNorm1d(num_filters)\n",
    "        \n",
    "        self.out = nn.Linear(2 * num_filters, 1)\n",
    "        self.norm_out = nn.BatchNorm1d(1)\n",
    "        \n",
    "    def forward_one(self, obj):\n",
    "        obj = self.embedding(obj)\n",
    "        obj = obj.mean(dim=1)\n",
    "        obj = F.sigmoid(self.hidden(obj))\n",
    "        obj = self.norm_hidden(obj)\n",
    "        \n",
    "        return obj\n",
    "        \n",
    "    def forward(self, d, q):\n",
    "        d = self.forward_one(d)\n",
    "        q = self.forward_one(q)\n",
    "        \n",
    "        h1 = d * q\n",
    "        h2 = d + q\n",
    "        \n",
    "        x = torch.cat((h1, h2), 1)\n",
    "\n",
    "        x = self.out(x)\n",
    "        x = self.norm_out(x)\n",
    "        \n",
    "        #x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Ranker(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.model = SiameseDAN(self, vocab_size, embedding_dim, pretrained_embeddings, ...)\n",
    "    \n",
    "    def forward(self, query, d1, d2):\n",
    "        d1 = self.model(query, d1)\n",
    "        d2 = self.model(query, d2)\n",
    "        \n",
    "        return F.log_softmax([d1, d2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size, embeddings_dim = title_field.vocab.vectors.shape\n",
    "\n",
    "clf = SiameseDAN(vocab_size, embeddings_dim, title_field.vocab.vectors, num_filters=20, mode='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, loss, iterable, training=True):\n",
    "    batch_accs, batch_losses = [], []\n",
    "    epoch_start = time.time()\n",
    "    for batch in tqdm(iterable, total=len(iterable)):\n",
    "        d, q, y = batch.title.t(), batch.query.t(), batch.label\n",
    "        \n",
    "        y = y\n",
    "        \n",
    "        if training:\n",
    "            model.zero_grad()\n",
    "\n",
    "        out = model(d, q)\n",
    "        _, preds = torch.max(out, 1)\n",
    "\n",
    "        accuracy = torch.mean(torch.eq(preds, y).float())\n",
    "        batch_loss = loss(out, y)\n",
    "\n",
    "        if training:\n",
    "            batch_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), .25)\n",
    "            opt.step()\n",
    "\n",
    "        batch_accs.append(accuracy.data[0])\n",
    "        batch_losses.append(batch_loss.data[0])\n",
    "\n",
    "        del d, q, y\n",
    "    \n",
    "    epoch_end = time.time()\n",
    "    return np.mean(batch_accs), np.mean(batch_losses), epoch_end - epoch_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:02<00:00, 150.41it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.79it/s]\n",
      "  1%|          | 2/316 [00:00<00:17, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5634580552577972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:03<00:00, 89.25it/s] \n",
      "100%|██████████| 6/6 [00:00<00:00,  8.42it/s]\n",
      "  1%|          | 2/316 [00:00<00:16, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:03<00:00, 101.89it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.88it/s]\n",
      "  1%|          | 2/316 [00:00<00:17, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:02<00:00, 109.69it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.91it/s]\n",
      "  1%|          | 3/316 [00:00<00:10, 28.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:02<00:00, 111.66it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.84it/s]\n",
      "  1%|          | 2/316 [00:00<00:16, 18.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:03<00:00, 101.61it/s]\n",
      "100%|██████████| 6/6 [00:01<00:00,  5.85it/s]\n",
      "  1%|          | 2/316 [00:00<00:16, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:03<00:00, 104.85it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.17it/s]\n",
      "  0%|          | 1/316 [00:00<00:33,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:03<00:00, 104.49it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.94it/s]\n",
      "  1%|          | 2/316 [00:00<00:15, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:03<00:00, 105.15it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.93it/s]\n",
      "  1%|          | 2/316 [00:00<00:16, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:02<00:00, 106.12it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  8.51it/s]\n",
      "  1%|          | 2/316 [00:00<00:15, 19.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316/316 [00:02<00:00, 110.99it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00,  9.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978359192609787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(filter(lambda p: p.requires_grad, clf.parameters()), lr=3e-3)\n",
    "loss = nn.NLLLoss()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "init_acc, _, _ = run_epoch(clf, loss, train_iter, training=False)\n",
    "best_acc, _, _ = run_epoch(clf, loss, test_iter, training=False)\n",
    "\n",
    "trn_losses, trn_accs = [0.], [init_acc]\n",
    "val_losses, val_accs = [0.], [best_acc]\n",
    "\n",
    "print(best_acc)\n",
    "\n",
    "for epoch in range(10):\n",
    "    clf.train()\n",
    "    trn_acc, trn_loss, trn_time = run_epoch(clf, loss, train_iter, training=True)\n",
    "    trn_losses.append(trn_loss)\n",
    "    trn_accs.append(trn_acc)\n",
    "        \n",
    "    clf.eval()\n",
    "    val_acc, val_loss, val_time = run_epoch(clf, loss, test_iter, training=False)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "    \n",
    "    print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qid_field = Field(sequential=False)\n",
    "did_field = Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_dataset = TabularDataset(\n",
    "    path='topics.csv', format='csv',\n",
    "    fields=[('qid', qid_field),('query', query_field)]\n",
    ")\n",
    "\n",
    "qid_field.build_vocab(query_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_dataset = TabularDataset(\n",
    "    path='docs_no_header.csv', format='csv',\n",
    "    fields=[('ix', None), ('did', did_field), ('text', None), ('title', title_field)]\n",
    ")\n",
    "\n",
    "did_field.build_vocab(docs_dataset)\n",
    "\n",
    "docs_iter = BucketIterator(docs_dataset, batch_size=2048, device=-1, sort_key=lambda x: len(x.title), repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:44<00:00,  2.62s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs = {}\n",
    "for example in tqdm(query_dataset.examples):\n",
    "    query = query_field.numericalize([example.query], device=-1)\n",
    "    results = None\n",
    "    for batch in docs_iter:\n",
    "        nd = batch.title.t()\n",
    "        nq = query.t().repeat(nd.shape[0], 1)\n",
    "        \n",
    "        labels = clf(nq, nd).data\n",
    "        ds = batch.did.data\n",
    "        \n",
    "        new_results = torch.cat((labels, ds.view(-1, 1).float()), dim=1)\n",
    "        \n",
    "        if results is None:\n",
    "            results = new_results\n",
    "        else:\n",
    "            results = torch.cat((results, new_results), dim=0)\n",
    "        \n",
    "        del nd, nq, new_results, labels, ds\n",
    "    \n",
    "    #print(results[:100])\n",
    "    _, dims = torch.topk(results[:, 1], k=1000, largest=True)\n",
    "    #print(dims[:100])\n",
    "    outputs[example.qid] = results[dims][:, 1:]\n",
    "    #print(outputs)\n",
    "    del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('test.results', 'w') as fp:\n",
    "    for qid, tensor in outputs.items():\n",
    "        for row in tensor:\n",
    "            docid = did_field.vocab.itos[int(row[1])]\n",
    "            fp.write(f'{qid} Q0 {docid} 0 {row[0]} PSE\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LEMONDE94-001555-19940819'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "did_field.vocab.itos[int(outputs['1'][0, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "def paired_shuffle(*args):\n",
    "    paired = list(zip(*args))\n",
    "    np.random.shuffle(paired)\n",
    "    return [np.array(l) for l in zip(*paired)]\n",
    "\n",
    "def sample_docs(qrels, topics, n_irr=4):\n",
    "    rel = qrels.qrels_data[qrels.qrels_data.rel == 1.0]\n",
    "    irr = qrels.qrels_data[qrels.qrels_data.rel == 0.0]\n",
    "    \n",
    "    samples, gold = [], []\n",
    "    for doc in rel.itertuples():\n",
    "        # get the possible negative documents\n",
    "        pool = irr[irr['query'] == doc.query]\n",
    "        # randomly sample from the possible negative documents\n",
    "        data = np.random.choice(pool.filename.values, n_irr)\n",
    "        data = [doc.filename] + list(data)\n",
    "        labels = np.array([1,] + [0,]*n_irr)\n",
    "        # shuffle the data and labels\n",
    "        data, labels = paired_shuffle(data, labels)\n",
    "        samples.append(data) ; gold.append(labels)\n",
    "    return np.array(samples), np.array(gold)\n",
    "\n",
    "docs, labels = sample_docs(qrels, topics, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4984, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py36)",
   "language": "python",
   "name": "conda_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
