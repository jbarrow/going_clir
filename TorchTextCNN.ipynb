{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchtext.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.autograd import Variable\n",
    "from torchtext.datasets import IMDB\n",
    "from vectors import MultiCCA, VectorVocabField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH=373\n",
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectors=GloVe(name='6B', dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, pretrained_embeddings, \n",
    "                 num_filters=100, window_sizes=(3, 4, 5), mode='static', num_classes=2):\n",
    "        super(ConvClassifier, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "        self.embedding.weight.requires_grad = (mode == 'nonstatic')\n",
    "        \n",
    "#         self.hidden = nn.Linear(embedding_dim, num_filters)\n",
    "#         self.out = nn.Linear(num_filters, num_classes)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, [window_size, embedding_dim], padding=(window_size - 1, 0))\n",
    "            for window_size in window_sizes\n",
    "        ])\n",
    "    \n",
    "#         self.norms = nn.ModuleList([\n",
    "#             nn.BatchNorm2d(num_filters) for window_size in window_sizes\n",
    "#         ])\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(num_classes)\n",
    "\n",
    "        self.fc = nn.Linear(num_filters * len(window_sizes), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)           # [B, T, E]\n",
    "#         x = x.mean(dim=1)\n",
    "#         x = F.sigmoid(self.hidden(x))\n",
    "#         x = F.softmax(self.out(x), dim=1)\n",
    "        \n",
    "#         return x\n",
    "        \n",
    "        # Apply a convolution + max pool layer for each window size\n",
    "        x = torch.unsqueeze(x, 1)       # [B, C, T, E] Add a channel dim.\n",
    "        xs = []\n",
    "        for conv in self.convs:\n",
    "            x2 = F.relu(conv(x))        # [B, F, T, 1]\n",
    "            x2 = torch.squeeze(x2, -1)  # [B, F, T]\n",
    "#             x2 = norm(x2)\n",
    "            x2 = F.max_pool1d(x2, x2.size(2))  # [B, F, 1]\n",
    "            xs.append(x2)\n",
    "        x = torch.cat(xs, 2)            # [B, F, window]\n",
    "\n",
    "        # FC\n",
    "        x = x.view(x.size(0), -1)       # [B, F * window]\n",
    "        logits = self.fc(x)             # [B, class]\n",
    "        \n",
    "        logits = self.norm(logits)\n",
    "\n",
    "        # Prediction\n",
    "        probs = F.softmax(logits, dim=1)       # [B, class]\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# allows us to generate \n",
    "def preprocess(l):\n",
    "    nopunct = [s.translate(translator) for s in l]\n",
    "    return [s for s in nopunct if s and s in vectors.stoi]\n",
    "\n",
    "# needed because `split` subclasses dataset, and thus doesn't have a\n",
    "# proper sort key\n",
    "def sort_key(ex):\n",
    "    return len(ex.text)\n",
    "\n",
    "text_field = VectorVocabField(lower=True, preprocessing=preprocess)\n",
    "#text_field = GloVeField(lower=True, preprocessing=preprocess, fix_length=MAX_LENGTH)\n",
    "label_field = data.Field(sequential=False, unk_token=None, pad_token=None)\n",
    "\n",
    "train, test = IMDB.splits(text_field=text_field, label_field=label_field)\n",
    "train, val = train.split(split_ratio=0.7)\n",
    "train.sort_key = sort_key\n",
    "val.sort_key = sort_key\n",
    "\n",
    "text_field.build_vocab(train, vectors=vectors)\n",
    "label_field.build_vocab(train)\n",
    "\n",
    "train, val, test = data.BucketIterator.splits(\n",
    "    (train, val, test), batch_sizes=(128, 128, 128), device=-1, repeat=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = next(iter(val)).text.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superb movie very good photography of bolton which seems now to be a different world thoughtful and an excellent dramatisation and production james mason a real first class star it is and i would agree with the above comment that this movie is a national treasure\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for example in examples:\n",
    "    print(' '.join([text_field.vocab.itos[num.data[0]] for num in example]))\n",
    "    print('')\n",
    "    break\n",
    "#clf(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_field.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size, embeddings_dim = text_field.vocab.vectors.shape\n",
    "\n",
    "clf = ConvClassifier(vocab_size, embeddings_dim, text_field.vocab.vectors, num_filters=20, mode='static')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(model, loss, iterable, training=True):\n",
    "    batch_accs, batch_losses = [], []\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    for batch in tqdm(iterable, total=len(iterable)):\n",
    "        x, y = batch.text.t(), batch.label\n",
    "        y = y * 2 - 1\n",
    "        \n",
    "        if training:\n",
    "            model.zero_grad()\n",
    " \n",
    "        out = model(x)\n",
    "        _, preds = torch.max(out, 1)\n",
    "        \n",
    "        accuracy = torch.mean(torch.eq(preds, y).float())\n",
    "        batch_loss = loss(out, y)\n",
    "        \n",
    "        if training:\n",
    "            batch_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), .25)\n",
    "            opt.step()\n",
    "            \n",
    "        batch_accs.append(accuracy.data[0])\n",
    "        batch_losses.append(batch_loss.data[0])\n",
    "        \n",
    "        del x, y\n",
    "    \n",
    "    epoch_end = time.time()\n",
    "    return np.mean(batch_accs), np.mean(batch_losses), epoch_end - epoch_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.eq received an invalid combination of arguments - got (torch.LongTensor, float), but expected one of:\n * (torch.LongTensor tensor, int value)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n * (torch.LongTensor tensor, torch.LongTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n * (torch.LongTensor tensor, int value)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n * (torch.LongTensor tensor, torch.LongTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d549322a4b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minit_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-19edf7bf45aa>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(model, loss, iterable, training)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhinge_embedding_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mhinge_embedding_loss\u001b[0;34m(input, target, margin, size_average)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHingeEmbeddingLoss\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m     \"\"\"\n\u001b[0;32m-> 1298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHingeEmbeddingLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/torch/nn/_functions/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, target, margin, size_average)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.eq received an invalid combination of arguments - got (torch.LongTensor, float), but expected one of:\n * (torch.LongTensor tensor, int value)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n * (torch.LongTensor tensor, torch.LongTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n * (torch.LongTensor tensor, int value)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n * (torch.LongTensor tensor, torch.LongTensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[32;1mtorch.LongTensor\u001b[0m, \u001b[31;1mfloat\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "opt = optim.Adam(filter(lambda p: p.requires_grad, clf.parameters()), lr=3e-3)\n",
    "loss = nn.NLLLoss()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "init_acc, _, _ = run_epoch(clf, loss, train, training=False)\n",
    "best_acc, _, _ = run_epoch(clf, loss, val, training=False)\n",
    "\n",
    "trn_losses, trn_accs = [0.], [init_acc]\n",
    "val_losses, val_accs = [0.], [best_acc]\n",
    "\n",
    "print(best_acc)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    clf.train()\n",
    "    trn_acc, trn_loss, trn_time = run_epoch(clf, loss, train, training=True)\n",
    "    trn_losses.append(trn_loss)\n",
    "    trn_accs.append(trn_acc)\n",
    "        \n",
    "    clf.eval()\n",
    "    val_acc, val_loss, val_time = run_epoch(clf, loss, val, training=False)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "    \n",
    "    print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faedd626f28>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xl8nWWd9/HPlT3N2jRJk2ZtupDu\ntIQWSgsFZBEFFAUKMqKiDKPgrqPjPOLjjKPjMo+OO4O4AwIqdGYqOANFCrI0oftKm71pmqTZ9+Vc\nzx/3aXIaSpu2ObnPuc/3/XrllZPTOzm/A8k3V373df+OsdYiIiLeEuV2ASIiMvkU7iIiHqRwFxHx\nIIW7iIgHKdxFRDxI4S4i4kEKdxERD1K4i4h4kMJdRMSDYtx64MzMTFtcXOzWw4uIhKWKiooWa23W\n6Y5zLdyLi4spLy936+FFRMKSMaZmIsepLSMi4kEKdxERD1K4i4h4kMJdRMSDFO4iIh6kcBcR8SCF\nu4iIB7m2z11ExPN8Pug9Bl1HoKsRuhqc9/OuhrwVQX1ohbuIyJmyFgY6naDu9Ad215GAt8axN9/Q\nmz8/KVPhLiIypYb6AgL6CHSOD2x/mA/1vvlz49MgJQdSc6F4jXM7JTfgLQeSZ0JMXNCfhsJdRLzv\n+Eq7uxl6mqGnCbqbxkI7cPXd3/7mz49J8Af1LMg9H+bnOgF+PLCPv49Lmvrn9hYU7iISnnw+6Gt1\nQrrHH9rdTU5w9zT7g7xpLNBHBt78NUy0s5JOzYUZc6D4khNX2Sn+EE9IB2Om/jmeA4W7iISOkaGA\nkG4ZW2GfEN7+970tYH1v/hpRMZCU5fS1k7Ihq3TsdnL2uNtZEBU99c9zCijcRWRqWOsEdmvliW9d\njWMhfrKWCEBMIiRnOaGcXuicjHyrsE5Ihyjt8la4i8jksRa6j745wFsrobXK6XsfZ6IgrQBS8yB7\nAcy+zAnn4yEeGNzxye49pzClcBeRM+PzOSceTxberZUw1DN2bFQMpBdBRgkUXOS8zyhx+ttpBVOy\nayRSKdxF5M18PuisP3l4t1bBcN/YsVGxML3YCezZa/0BPtt5n1YI0YoZN+i/ukikGuyFjjpor4W2\n6oDwrnQ+DtxdEh0/FthzrhhbgWeUQFq+Z09KhjOFu4hXDXRBe91YgLfXOB+31zpvvS0nHh+T6IR1\n5jyYf81Y+ySjxNnfrZOUYUXhLhKu+jtODOuOOn+A1zr397WeeHx0PKQXOLtNcpY479OLxu5LyQ27\nvdzy1hTuIqHIWmdb4PGgPlmA93ec+DkxiWNBnXeB8z6twB/ghf493Vp9RwqFu4ibhgehZT807oSj\nu+HYobEQD9w2CBCb5F9tF0LBqrHbaf73SZlaecsohbvIVOk5Bkd3QuMuf5jvgub9Y1MDYxIgY44T\n1MVrxlbhx9snidMV3jJhCneRyeYbcXacNO5wgvzoLud9V8PYMck5kLMY5r7N6X/nLHGCXdsGZZLo\nO0nkXAx0Oe2U4yvxxp3QtHdsHGxUDGSe5+z/nrnYCfSZS5yrMEWCSOEuMhHWOn3w0ZaKv73SVjV2\nTEK6swJfcad/Nb7YGVoVE+9e3RKxFO4i4w31Q/PegJaKf1U+ujvFOHu/c5fC+e9zQjxniTMjRT1x\nCREKd5HeVqh9BWr/CjV/hSPbwTfs/FtsEsxcCItuGuuNZy/UICsJeQp3iTwdh6H2ZSfIa/7qrNIB\nouOc/eGr74PcZZCzFKbP1t5wCUsKd/E2a5294zUvjQV6e43zb3EpULASlrwHClc7wR6b4G69IpNE\n4S7e4htx+uPHV+W1Lzuv3AMwLROKLoZV9zjvZy7R1kPxLH1nS3gbHoDDr4/1y+teG7uyM60Q5lzp\nBHnhamcglk54SoRQuEt4GeiCuleh5mVnVV5fPjaaNqsUFr8Hii5xAj0t391aRVykcJfQ1tMy1l6p\n+atz1af1Oa9an7sMVn4ECi923pJmuF2tSMhQuEtosRYaXoedT8DB/4WWA879MQmQfyGs/ayzKs9f\nqe2IIqcwoXA3xlwLfA+IBh601n5j3L8XAQ8BWUArcIe1tn6SaxUvazkIOx933loPOdsSZ18G59/u\n9Mtnna8rPUXOwGnD3RgTDfwQuAqoB7YYYzZYa/cEHPZt4FfW2l8aY64Avg78TTAKFg/paoRdv3cC\nvWErYJwZLGs+BQuuh8R0tysUCVsTWbmvBA5aaysBjDGPAjcCgeG+EPi0//Ym4MnJLFI8pL8D9v4n\n7HgMqjc7/fPc8+HqrzknQ1Nz3a5QxBMmEu55QF3Ax/XAqnHHbAduwmndvBtIMcbMsNYem5QqJbwN\n9cMbf3ZW6AeecXa3TJ8Nl34OFr8Xsua7XaGI50zWCdXPAj8wxnwAeAE4DIyMP8gYczdwN0BhYeEk\nPbSEJN8IVL8IOx+DPf8JAx2QlA1lH4IlN0PeCu05FwmiiYT7YaAg4ON8/32jrLUNOCt3jDHJwHus\nte3jv5C19gHgAYCysjJ7ljVLqLIWjmxzdrrs+j10HXEu8V9wPSy9GYov1RWhIlNkIj9pW4B5xpjZ\nOKG+Hrg98ABjTCbQaq31AV/E2TkjkeLYISfQdz4Ox96AqFiYfw0seS/MvxZiE92uUCTinDbcrbXD\nxph7gWdwtkI+ZK3dbYz5KlBurd0ArAO+boyxOG2ZjwWxZgkFXUdh9x+dtsvhCsA4r/u5+l5YeKPz\nep8i4hpjrTvdkbKyMlteXu7KY8tZ6u+Eff/lrNArn3d2uuQsgSW3ODtd0vLcrlDE84wxFdbastMd\npwaonNrwgHOl6I7H4MDTMNwP6UWw5tPOidHsUrcrFJGTULjLmw0PQuUm2POUs1Lv73DG5a54vxPo\n+Rdqp4tIiFO4i2Oo3wn03U/C/j85Wxfj06D0OmcvesllEB3rdpUiMkEK90g21AcHn3VW6Pv/BINd\nkJDubF1ceCOUrIOYOLerFJGzoHCPNIO9Tg99z5PO1aKD3c7OlkXvct5ma4Uu4gUK90gw2ONc/r/n\nKTjwZxjqgWkznH3oC2+E4rUKdBGPUbh71UA3vPGM00N/439guA+SsmDZrbDwXc6rFelqURHP0k+3\nl/R3Oq2WPU86rZfhfkieCcvvcFboRashKtrtKkVkCijcw11/B+x/2h/ozzoTF1NyYcWdTg+9YJUC\nXSQCKdzDUV+bs7tl95PO9sWRQUjNgwvvclbo+SshKsrtKkXERQr3cNHbCvv+2zkpWvk8+IYgrQBW\n3u0Eel6ZAl1ERincw8FfvgV/+Qb4hiG9EC66Bxa+WzPRReQtKdxD3baHYdM/O6vzSz4Js5Yr0EXk\ntBTuoaz6JdjwcZh9KbznZ9qLLiITpiZtqDp2CH73PpheDLf8SsEuImdE4R6K+trg4Vud27f/Ti98\nISJnTG2ZUDMyBI/dCW3V8P6nYMYctysSkTCkcA8l1sLGz0LVX+BdP4biS9yuSETClNoyoeSVH0HF\nL5xXOTr/9tMeLiLyVhTuoWL/n+CZL8GCG+CK/+N2NSIS5hTuoaBxJzxxF+Qug3f/VFeaisg5U4q4\nravR2RmTmA63PQpx09yuSEQ8QCdU3TTYC4/cBn3t8KGnITXX7YpExCMU7m7x+eDJe6BhK6x/GHKX\nnvSwoREflc09xMdEUZyZNMVFiki4Uri7ZdM/OxMer/5nKL0Oay2Nnf3sa+xi35Eu9jd2sq+xi0PN\n3QyNWBJjo/nP+9YwNzvZ7cpFJAwo3F3Qt+U3JG7+Dgfzb+JXTevY95OX2dfYSWf/8OgxuWkJnJeT\nwrrzsinJSuLrG/dy3yNb+eNHV5MQqxffEJFTU7gH0fCIj6qWHmc13tjJ/sYu4g6/yncHvsxLvkXc\nefBdJNQ1cF5OCu9cNovSnBRKc1I5b2YKadNOnCUzIymOu35Zzr8+vY/7r1/k0jMSkXChcJ8E1lqO\ndg6MBvj+xi72NnZxqKmbwREfANFRhksyOvnuyL/SMy2foWt+wabCfPKnJ2ImMML3ygUz+cDqYn7+\nUjVr5mZy5YKZwX5aIhLGFO5nqGdgmP1HnQDfd8Tpi+8/2kV779DoMTmpTkvl0nmZnOdfjc9JHSb+\nF9fASDR8+I+sO4uZMV+8rpTXqlr53BM7+NMn1jIzNWEyn1rEO9zex3P7mthe105JVhLn56ezJD+N\nlARN5JTwY6y1rjxwWVmZLS8vd+Wxz8aIz/Len/yVrbXto/clxUUzPydlrJ3iv50+LW7cJw/Bb9/r\nzGd//5NQvOas6zjY1M3133+R5YXp/PquVURH6YU7ztaIz7K1to1n9zWxaV8T+xq7AJg+LZY2/y9r\nY2BOVjLL8tNZVpDGsvx0SnNTiI/ReQ9xhzGmwlpbdrrjtHKfoL1HOtla287NF+Rz1cKZLMhNJS89\nkajThau1sPFzzuue3vijcwp2gLnZyfzfGxbx+d/v4KcvHOKj6+ae09eLNO29g/zlQDOb9jXx/IFm\n2nuHiIkyXFicwZeuW8AVC7IpyUyivXeIHYc72F7Xzva6dv5yoInfv14PQFx0FAtmpbIsP80f+umU\nZCad/ntBZAop3CeooqYNgE+8bR7508/gKtJXfgwVP4c1n4Ll75uUWm4uy+eFN5r5zp8PcFHJDFYU\nat77W7HW8kZTN8/ta+K5vU1U1LYx4rNkJMVxRWk2V5Rms3ZeFmmJJ7ZepifFcdn8LC6bnzX6dRo6\n+kfDfnt9O7+vqOdXL9cAkBIfw1L/yn5pfjrnF6STk6a2mYypb+tlS3Urr1W18Z4VeZQVZwT18RTu\nE1Re00ZOagJ56YkT/6T9T8Mz/wALrocrvjxptRhj+Nq7l7Ctrp2PP7KVjZ9YS6r6wqP6h0Z4pfKY\nE+j7mqhv6wNgYW4qf3fZHK5YkM2y/PQzamkZY8hLTyQvPZHrljhXEo/4LIeau9nmD/wd9R088EIl\nwz6n1TkzNX50Zb/M378f/0skkvUMDFN9rIcZSfHMTI2f0MaCcGGt873xalUrW6pa2VLdxuF25/sw\nJSGGC4qmBz3c1XOfoNVff5blRdP54e0rJvYJjTvhZ9dA5jz44EaIm/yrSytq2rjlpy/z9sU5fP+2\n5Z764ThTjR39o2H+0sEW+oZGSIiNYs3cTK4oncnlpVnkpp3BL+az1D80wp4jnaMr/B31HVS29Iz+\n+/ETtUvz01hWkM6C3FRPX7dwfCfZoeZu562pm0PNPVQ2d9PQ0T96XGZyHAtnpbF4ViqL89JYPCuN\ngoyJ7SQLBcMjPvYc6eS1qlZeq2qlvKaN1p5BALJS4llZnMGFxdNZOXsG5+WknNO5MvXcJ1FDex8N\nHf18pGiC7Y+uRnh4PSSk+YeBBWdswAVF0/n0VfP51jP7uXR+FreUFQTlcULRiM+yvb6dTfuaeHZv\nE3uOdAKQl57IzWX5XF6azcUlM6Y8OBNio1lROP2EVllH7xA7Dh9v53Sw+WALf9h6GIDYaMOC3FQn\n7PPTKclKJjslnszkeBLjwif0+4dGqDnWGxDgYyHeMzgyelxyfAwlWUmsKpnBnKwkijOTaOkaYFdD\nJ7sbOk/4yyclIYZFs1JZPCuNRXnO+5Ks5JDYRNA/NMK2una2VLXyWnUrr9e0jT7PwoxpXFGa7QT6\n7AyKZ0xz5ZeUwn0Cyv399rKiCfwZNdTnHwbWOiXDwO65bA4vvtHC/U/t5oKi6czJ8u54gs7+ITYf\naOHZfUf5y/5mjvUMEmWc/y9/f20pVy7IZl52csit9tKmxbJ2XhZr54317xs7+0fDfntdO09ubeA3\nr9Se8HlJcdFk+YM+Mzl+7HZKHFnJ8WSmxDvvp+gXgbWWYz2DHGrqprKl54QQr2vrJbAJkJeeSElW\nEjeXFTAnK4k5WcnMyXZ+cZ3q/0//0AgHjnax63Anuxs62NXQya9fqWFg2LleJDE2mtLcFBbPSmNx\nXiqLZqUxf2YKcTHBHXDb2T9ERU0br/nbLDvqO0avYSnNSeGmFfmsnJ3BytkZIbNFWW2ZCbj/qV08\nXlHPjvuvJib6FN9EPh888UFnZsz630LpO6akvsaOft7+vRfITUvkjx9b7ZltetZaKlt6eG6v027Z\nUt3KsM+SlhjLuvOyuKI0m8vmZ71562kY8vkslS3d1LX20dw9QHPXAC3dA7R0D9Lc1U9L9yAt3QMn\nXE8RKDk+hszkuJP/Mgi4Pysl/rR/zQyN+Kht7T1piHf0jT1+fEwUJVnJo+FdEvB+WtzkrRuHR3wc\nau5h1+EOdjV0sLuhkz0NnXQPOOM6YqMN82emjK7wF81KY0FuyjnV0Nw14D/56bzta+zEZyEmyrAk\nP83fZsmgrHj6lH//TbQto3CfgHf8+2bSEmN5+CMXnfrAZ/8JNn8brvonuOTjU1Oc3//uOcqHf1XO\nhy6ZzZevXziljx0Mv3q5moderKL6WC8A581M4fLSbK5ckM3ygvRT/5L1sMFhH8d6BmjpGqS5u9//\nPvCXwfHbgycEcaCU+BgyU04M/YTYaKpbejjU3E3Nsd7R1gg4PePR1bd/BV6SmTSxrcBB4vNZalp7\nndX98VX+4Y7R6xOiDJRkJY/28BfNSmPhrNSTntC21lLf1hdw8rN19DxJQmwUKwqnO6vy4gzOL0yf\n1F9cZ2NSe+7GmGuB7wHRwIPW2m+M+/dC4JdAuv+YL1hrN55x1SGoe2CYvUc6uffy0+wn3/6oE+wr\n3g+r75ua4gK8baEznuChl6pYM28GV5SG53gCay3feHofP/1LJRcWT+euNbO5vDT7zLafelhcTBS5\naYn+k8Nppzx2YHiEY/4Vf2DoN3cN0Nw9QEvXAPsbu3ixq4X+IR9FM6YxNzuZaxbljIV4VlJI7sSK\nijLMzkxidmYS71w6C3C+d4509PtX+J3saejglcpWntzWMPp5hRnTRts5KQkxlFc7rZbGTufkbmpC\nDCtnZ3DrhQWsnJ3B4rw0YsN0IXHacDfGRAM/BK4C6oEtxpgN1to9AYf9I/CYtfbHxpiFwEagOAj1\nTrltte34LFxwqm1LNS/DhvugeC1c9x3nskYXfOHtpbxa1cpnH9/B059YS3aI9P4masRn+ccnd/LI\na3W8b1UhX71xcUicPAtX8THRzEpPZNYEtu9aa0PuXMWZMsaMPt+rF+WM3t/SPcDuhk52He5gt7+t\ns3FnI+BsV72wOINVs52Tn/OzUzxzMdpEVu4rgYPW2koAY8yjwI1AYLhbINV/Ow1owCPKa1oxBpYX\npp/8gNZKePR2SC+EW38NMe71fxNio/n+bcu5/vsv8qnHtvHrD60Km2/UgeERPv277fz3ziPce/lc\nPnP1/LAPm3Di5f/WmcnxJ1yQBtDRN0T3wDCz0hI8+9wn8vdGHlAX8HG9/75AXwHuMMbU46zaT9qX\nMMbcbYwpN8aUNzc3n0W5U6+ipo3zZqac/E/Tvnbn9U+xcPtjkOj+laJzs5P5yg0LeengMX76QqXb\n5UxI7+AwH/5lOf+98whfum4Bn73mPM/+wEloSEuMJS89fPbRn43JaibdBvzCWpsPXAf82hjzpq9t\nrX3AWltmrS3Lysp60xcJNc5gqXbKik8S2iND8PgHoLUKbv0NnMWUx2C5payAdyzN5Tt/3s/W2ja3\nyzmljt4h7njwVV462MI337OUj1xa4nZJIp4wkXA/DAReHZPvvy/QXcBjANbal4EEIHMyCnTTvkZn\nu9Wb9rdbC3/6PFRuguu/e87DwCabMYZ/efcSZqYm8PFHt9LZf/JdE25r6uzn1gdeZtfhTn70vhXc\ncmHkXIQlEmwTCfctwDxjzGxjTBywHtgw7pha4EoAY8wCnHAPj77LKRwfFnbB+CtTX/0JlD8El3wS\nlt/hQmWnl5YYy7/fdj4N7f384x934daW17dSe6yX9/7kZWpbe3noAxdy7eLgXuwlEmlOG+7W2mHg\nXuAZYC/OrpjdxpivGmNu8B/2GeAjxpjtwCPAB2yopclZKK9uY2ZqPPnTA3YbHHjGGQZW+k648n73\nipuAC4oy+NTb5rFhewNPVNS7Xc6o/Y1dvPcnf6Wjb4jffngVa+aF/R95IiFnQvvc/XvWN46778sB\nt/cAl0xuae6rqGmjrChj7KRL4y544kOQswRuegCiQn//69+tm8uLB1u4f8NuVoTAeILXa9v44M+3\nkBAbxeP3XMz8mSmu1iPiVaGfTi450tHH4fa+sZbMyBA8ehvEp8JtvwvaMLDJFh1l+O6ty4mLieLj\nj2xlYHjk9J8UJJvfaOaOB18lfVosT9yzWsEuEkQK97dQXu0fFnZ8p0x9ObTXwjVfC/owsMmWk5bA\nt967jN0NnXzz6f2u1PCnnUf40C+2UJgxjcfvuZiCDF1xKhJMCve3UFHTRmJsNAty/ddmVW4CEwVz\nLne3sLN01cKZ3HlxET97sYpN+5qm9LF/t6WWjz38Okvz0/nd3ReTnRJeV86KhCOF+1sor2nl/IL0\nsbkShzbBrOUhcaHS2fridQsozUnhs49vp6mz//SfMAkeeOEQf//7naydl8Wv71pJ2rTQm1Mi4kUK\n95PoGRhm75GusZZMXzscLoc5V7hb2DlKiI3mB7cvp2dwmE8/th2fL3gbmqy1fPPpffzLxn28c2ku\n//H+Mten6YlEEoX7SWyra2fEZ8dOplZvBuuDkvBsyQSam53CV65fxIsHW3hgc3DGE4z4LF96chc/\nev4Qt68q5Hvrlwf9xRRE5ET6iTuJ8uo2jIEVx8P90CaITYL8C90tbJLcemEB71iSy7ef2c+2uvZJ\n/dqDwz4+8ehWHn61lo+um8PX3qXJjiJuULifRHlN64nDwg49B7PXujrxcTIZY/iXm/zjCR7ZStck\njSfoGxzhI78q5792HOGLby/l89eWenowk0goU7iPc3xY2GhLpq0a2qo80ZIJdHw8weH2Pv7xyXMf\nT9DRO8QdP3uVzW80842blvC3l4XOIDWRSKRwH2d/Y5czLKw4oCUDYbsF8lQuKMrgk1fO46ltDfzh\n9fGz4CauqcsZALajvp0f3L6C9SsLJ7FKETkbCvdxKmpaAcYmQR56DlLzIHO+i1UFz0cvn8uq2Rn8\nn6d2UdncfcafX9fay80BA8CuWxJeF3iJeJXCfZzymjayU/zDwnwjUPWC05LxaO84Osrw3fXnExcT\nxX1nOJ7gwFFnAFh77xC/+fAq1s4L/Rn9IpFC4T5OeXUbZcXTnROBDdugv92TLZlAuWmJfPM9S9nd\n0Mm3JjieYFtdO7f89GWshcf+9mJWFIbvxV0iXqRwD9DY0e8fFhbQkgEoWedWSVPm6kU5vP/iIh58\nsYpN+089nuClgy3c/h+vkJrgDAA7L0cDwERCjcI9QPlov92/Cq3cBDlLISky5o3/w/HxBI9tp6nr\n5OMJnt7VyAd/voWC6dN44p6LKZyhAWAioUjhHqC82hkWtnBWKgx0Qd1rnm/JBEqIjeb7tznjCT5z\nkvEEj5XX8dHfVrAoL5Xf/e1FZKdqAJhIqFK4B6ioaWNZQZozLKz6JfANhf08mTM1b2YKX37nIja/\n0cJ/BIwneHBzJZ9/YgeXzM3ktx9eRfo0b1zQJeJVmuTk1zMwzJ4jnfzd8YtvKjdBTAIUXORuYS64\nbWUBLx5s5lvP7GdVyQz+d89RfrDpIO9Yksu/3bqM+Jhot0sUkdNQuPttPz4sLPDipaLVEBt5rQdj\nDF9/91K2123mtgdeoW9ohPUXFvC1dy/RnBiRMKG2jF95jX9YWOF06DgMLfsjriUTKG1aLN9bfz4A\n91w2h6/fpGAXCSdaufuV17QxPzuFtMRY2OcfOeCxeTJnqqw4g+33X61xvSJhSD+1+IeF1bSd2JJJ\nyoaZi9wtLAQo2EXCk35ycS6j7xoYdva3+3zOydQ53h05ICLep3DHacmAf1jY0Z3QeyziWzIiEt4U\n7kBFdStZKfEUZCSOjfgtWedmSSIi50ThjrNyLyvyDws79BxkL4RUja4VkfAV8eF+tLOf+rY+55WX\nhvqg9hW1ZEQk7EV8uJdX+/vtxRlQ81cYGYioeTIi4k0K95pWEmKjWDQr1WnJRMc5V6aKiISxiA/3\nipo2luWnO8PCKp+HglUQl+R2WSIi5ySiw713cJjdDZ3Oi2F3HYWju9SSERFPiOhw3+YfFlZWlOGs\n2iGi58mIiHdEdLhX+E+mriic7lyVmpgBOctcrkpE5NxFdLiX17Qxf2YyaYkxzsVLJesgKqL/k4iI\nR0Rskvl8ltdr25wXw27aC92N6reLiGdEbLgfaOqiq98/LKxSI35FxFsiNtzHLl6a7rRkZsyD9AKX\nqxIRmRwTCndjzLXGmP3GmIPGmC+c5N//nzFmm//tgDGmffJLnVwVNW1kJsdTmBoN1S+qJSMinnLa\nV2IyxkQDPwSuAuqBLcaYDdbaPcePsdZ+KuD4+4DlQah1UpXXtDrDwupfg+E+tWRExFMmsnJfCRy0\n1lZaaweBR4EbT3H8bcAjk1FcsDR19lPX2jfWkomKgeI1bpclIjJpJhLueUBdwMf1/vvexBhTBMwG\nnjv30oLn+ItzXFA03Zknk38hJKS6XJWIyOSZ7BOq64EnrLUjJ/tHY8zdxphyY0x5c3PzJD/0xJVX\ntxEfE8Wi9BE4sl0tGRHxnImE+2EgcBtJvv++k1nPKVoy1toHrLVl1tqyrKysiVc5ySpqWllWkE5c\n7QuA1cgBEfGciYT7FmCeMWa2MSYOJ8A3jD/IGFMKTAdentwSJ1ff4IgzLOx4SyY+DWaF/PlfEZEz\nctpwt9YOA/cCzwB7gcestbuNMV81xtwQcOh64FFrrQ1OqZNjW107wz5LWVG6Myxs9lqIPu2mIRGR\nsDKhVLPWbgQ2jrvvy+M+/srklRU8FTWtAJSltEFHHaz51Gk+Q0Qk/ETcFarlNW3My04m9fBm5w5d\nvCQiHhRR4e7zWV6vaXP2t1dugvQiyChxuywRkUkXUeH+RlM3nf3DlBWkQNVm7ZIREc+KqHAv9/fb\nV8dXwWCXWjIi4lkRFe4V1W1kJseR0/IymCiYfanbJYmIBEVEhXt5TRsXFE3HVD4Ps1ZA4nS3SxIR\nCYqICfemrn5qW3tZPSsWDleoJSMinhYx4X78xbDXxO4BO6J5MiLiaRET7uU1zrCw4o7XIC7ZmQQp\nIuJRERXuy/LTia563pndHhOMvpY2AAAJUElEQVTndkkiIkETEeHeNzjC7sMdXJHTB62VasmIiOdF\nRLhvr3eGhV0Ws9O5QxcviYjHRUS4V/hfeWlO1xZIzYPMeS5XJCISXBER7uXVrczPSiSuZrPTkjHG\n7ZJERILK8+Hu81kqatq4IbsJ+tu1v11EIoLnw/1gszMs7LKYXc4dJevcLEdEZEp4PtzL/Rcvze3a\nAjlLISnT5YpERILP++Fe00r+tBESGiu0S0ZEIobnw72ipo1bs2sxviH120UkYng63Ju7Bqg51su6\nmF0QkwAFF7ldkojIlPB0uB9/Mey5XVug6BKITXC5IhGRqeHpcC+vbqMgpo3EjoNqyYhIRPF2uNe0\nsT7joPOB5smISATxbLj3D42wu6GDdbG7ISkbZi5yuyQRkSnj2XDfXtfO8MgI87rLnZaMRg6ISATx\nbLiX17Sx0NQSN9CqloyIRBzPhntFTRs3pux3PtDJVBGJMJ4M9+PDwi6P3Q3ZCyElx+2SRESmlCfD\n/VBzN/19PZT07dDIARGJSJ4M9/KaNlZG7SPaN6h+u4hEJG+Ge3UbV8XvwUbHQdFqt8sREZlyngz3\nippWLo/dhSm8COKmuV2OiMiU81y4N3cN0H3sCAWDlWrJiEjE8ly4V9S0cUnUTucDbYEUkQjlwXBv\nZV3MLmxiBuQsc7scERFXeC7cy6tbuSxmF6ZkHUR57umJiEyIp9Kvf2iE/obdZPha1ZIRkYjmqXDf\nUd/BanY4H+hkqohEsAmFuzHmWmPMfmPMQWPMF97imFuMMXuMMbuNMQ9PbpkTU17TypqonYxkzIX0\nAjdKEBEJCTGnO8AYEw38ELgKqAe2GGM2WGv3BBwzD/gicIm1ts0Ykx2sgk9le9VRPhi9j+i5d7rx\n8CIiIWMiK/eVwEFrbaW1dhB4FLhx3DEfAX5orW0DsNY2TW6Zp+fzWUZqXyWRAc2TEZGIN5FwzwPq\nAj6u998XaD4w3xjzkjHmFWPMtZNV4ERVtnSzfGgrPhMDxWum+uFFRELKadsyZ/B15gHrgHzgBWPM\nEmtte+BBxpi7gbsBCgsLJ+mhHeXVbayJ2sVAzgoS41Mm9WuLiISbiazcDwOBZyfz/fcFqgc2WGuH\nrLVVwAGcsD+BtfYBa22ZtbYsKyvrbGs+qT2HqlkSVUXCeW+b1K8rIhKOJhLuW4B5xpjZxpg4YD2w\nYdwxT+Ks2jHGZOK0aSonsc7Tiq5+gSgsRv12EZHTh7u1dhi4F3gG2As8Zq3dbYz5qjHmBv9hzwDH\njDF7gE3A56y1x4JV9Hgt3QPM7ylnICYZZi2fqocVEQlZE+q5W2s3AhvH3fflgNsW+LT/bcpVVLey\nNnonvXlriI+erNMIIiLhyxNXqFbt30G+aSF5wVVulyIiEhI8Ee5RVZsAiJ2vfruICHgg3PuHRijp\nfI22+DzIKHG7HBGRkBD24b6rroVVZg/debpwSUTkuLAP97qdL5Ji+khffLXbpYiIhIywD/foqk2M\nEEXKgivdLkVEJGSEdbhbaylqf5X6xFJInO52OSIiISOsw72qvoFF9qD67SIi44R1uDds+zMxxkfa\n4ikfQikiEtLCOtyjKp+nhwTyFq91uxQRkZAS1uFe2P4qBxPPx8TEuV2KiEhICdtwb6s/QL49Qmfe\npW6XIiIScsI23Bu2/glA+9tFRE4ibMM9qvJ5jtgM5i3UiF8RkfHCM9x9I+S3v8buxDIS4jTiV0Rk\nvLAM94HaClJsN9152iUjInIyYRnuLdufBiB1kV4vVUTkZMIy3E3lJnb6ilk6f47bpYiIhKTwC/eB\nbrI7drAzfgWZyfFuVyMiEpLCLtxt9YvEMEznLPXbRUTeSthtNTlWu4d4m0hGqcJdROSthN3K/bn0\nmykb+DEr5uS4XYqISMgKu3BPnxbLpQsLKMlMdrsUEZGQFXZtmasX5XD1Iq3aRUROJexW7iIicnoK\ndxERD1K4i4h4kMJdRMSDFO4iIh6kcBcR8SCFu4iIByncRUQ8yFhr3XlgY5qBmrP89EygZRLLCQd6\nzpFBzzkynMtzLrLWZp3uINfC/VwYY8qttWVu1zGV9Jwjg55zZJiK56y2jIiIByncRUQ8KFzD/QG3\nC3CBnnNk0HOODEF/zmHZcxcRkVML15W7iIicQtiFuzHmWmPMfmPMQWPMF9yuJ9iMMQXGmE3GmD3G\nmN3GmE+4XdNUMMZEG2O2GmP+y+1apoIxJt0Y84QxZp8xZq8x5mK3awo2Y8yn/N/Tu4wxjxhjEtyu\nabIZYx4yxjQZY3YF3JdhjPkfY8wb/vfTg/HYYRXuxpho4IfA24GFwG3GmIXuVhV0w8BnrLULgYuA\nj0XAcwb4BLDX7SKm0PeAp621pcAyPP7cjTF5wMeBMmvtYiAaWO9uVUHxC+Dacfd9AXjWWjsPeNb/\n8aQLq3AHVgIHrbWV1tpB4FHgRpdrCipr7RFr7ev+2104P/R57lYVXMaYfOAdwINu1zIVjDFpwKXA\nzwCstYPW2nZ3q5oSMUCiMSYGmAY0uFzPpLPWvgC0jrv7RuCX/tu/BN4VjMcOt3DPA+oCPq7H40EX\nyBhTDCwHXnW3kqD7LvB5wOd2IVNkNtAM/NzfinrQGJPkdlHBZK09DHwbqAWOAB3W2j+7W9WUmWmt\nPeK/3QjMDMaDhFu4RyxjTDLwe+CT1tpOt+sJFmPMO4Ema22F27VMoRhgBfBja+1yoIcg/akeKvx9\n5htxfrHNApKMMXe4W9XUs852xaBsWQy3cD8MFAR8nO+/z9OMMbE4wf5ba+0f3K4nyC4BbjDGVOO0\n3a4wxvzG3ZKCrh6ot9Ye/4vsCZyw97K3AVXW2mZr7RDwB2C1yzVNlaPGmFwA//umYDxIuIX7FmCe\nMWa2MSYO5wTMBpdrCipjjMHpxe611v6b2/UEm7X2i9bafGttMc7/3+estZ5e0VlrG4E6Y8x5/ruu\nBPa4WNJUqAUuMsZM83+PX4nHTyIH2ADc6b99J/BUMB4kJhhfNFistcPGmHuBZ3DOrj9krd3tclnB\ndgnwN8BOY8w2/33/YK3d6GJNMvnuA37rX7RUAh90uZ6gsta+aox5AngdZ0fYVjx4paox5hFgHZBp\njKkH7ge+ATxmjLkLZzLuLUF5bF2hKiLiPeHWlhERkQlQuIuIeJDCXUTEgxTuIiIepHAXEfEghbuI\niAcp3EVEPEjhLiLiQf8fe6tCsOcYxP8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faede0ce588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_accs)\n",
    "plt.plot(trn_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [00:13<00:00, 14.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8136718750608211, -0.7970627111439802, 13.195263624191284)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_epoch(clf, loss, test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py36)",
   "language": "python",
   "name": "conda_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
